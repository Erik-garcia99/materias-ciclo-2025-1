{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4ff91f-63e7-4239-9c22-d3f84505fcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac7a334-8bc9-47c9-a33b-5b20ec5001e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(A, THETA):\n",
    "    \"\"\"\n",
    "    Multivariate Linear Regression Model, Yh = A*THETA\n",
    "    The matrix A is sometimes called the design matrix.\n",
    "    \"\"\"\n",
    "    #hipotesis\n",
    "    return A.dot(THETA) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2ca0e89-da15-4a28-8462-3f359b29f6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design Matrix\n",
    "def designMatrix(Tau,X):\n",
    "    q,_ = X.shape\n",
    "    for p in range(q):\n",
    "        M = powerVector(Tau,X[p,:])\n",
    "        if p == 0:\n",
    "            A = M\n",
    "            continue\n",
    "        A = np.vstack((A,M))\n",
    "    return A\n",
    "\n",
    "# Power Vector\n",
    "def powerVector(Tau,V):\n",
    "    if V.size == 0 or Tau == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        M = np.array([])\n",
    "        Z = V[:-1]\n",
    "        W = V[-1]\n",
    "        for k in range(Tau+1):\n",
    "            value = powerVector(Tau-k,Z)*(W**k)\n",
    "            M = np.append(M,value)\n",
    "        return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ca778b6-b754-4061-a015-232b8c55a3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial parameter number\n",
    "def polyParamsNumber(n,tau):\n",
    "    s = 0\n",
    "    for l in range(tau+1):\n",
    "        val = np.math.factorial(l+n-1)/np.math.factorial(n-1)\n",
    "        val = val/np.math.factorial(l)\n",
    "        s = s + val\n",
    "    return int(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aabf335-98c9-4376-8519-e7b500e5f0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"funcion de costo. lamba se usa si se va a regularizar  \"\"\"\n",
    "def loss(Y_true, Y_pred, THETA, lambda_param):\n",
    "    \"\"\" Mean Squared Error \"\"\"\n",
    "    E = Y_true - Y_pred\n",
    "    SSE = np.square(np.linalg.norm(E, 'fro')) #funcion de osot \n",
    "    Reg = (lambda_param/(2*E.shape[0]))*np.square(np.linalg.norm(THETA[1:,:], 'fro')) #regularizacion, porque 1 en adenta la norma, eso seria si nos interesa los parametros \n",
    "    MSE = SSE/(2*E.shape[0]) + Reg\n",
    "    return MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77eabc5e-7e80-407e-bde9-bb5d76410200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(A,E,THETA,lambda_param):\n",
    "    \"\"\" MSE Gradient \"\"\"\n",
    "    SSEGrad = -1.0*(A.T).dot(E)\n",
    "    MSEGrad = SSEGrad/E.shape[0]\n",
    "    MSEGrad[1:,:] = MSEGrad[1:,:] + (lambda_param/E.shape[0])*THETA[1:,:]\n",
    "    return MSEGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0305205-cda7-417a-855c-f57fa5ab328c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic RMSprop\n",
    "def rmsprop_optimization(\n",
    "    X,\n",
    "    Y,\n",
    "    tau=1,\n",
    "    lambda_param=0.0,\n",
    "    maxEpochs=100,\n",
    "    show=10,\n",
    "    batch_size=16,\n",
    "    learning_rate=0.01,\n",
    "    stopping_threshold=1e-6,\n",
    "    beta=0.9,\n",
    "    epsilon=1e-8,\n",
    "):\n",
    "    \"\"\"\n",
    "    RMSprop optimization with support for mini-batches.\n",
    "    \"\"\"\n",
    "    # Initialize the model parameters randomly\n",
    "    n = X.shape[1] #varibales \n",
    "    m = Y.shape[1]#salidas que tengo, vairbaes objetivo \n",
    "    rho = polyParamsNumber(n,tau)\n",
    "    THETA = np.random.randn(rho,m)\n",
    "    # Initialize accumulators for squared gradients\n",
    "    this = \"RMSprop\"\n",
    "    S = np.zeros((rho,m)) # Momentum\n",
    "    q = X.shape[0]\n",
    "    n_minibatches = q // batch_size\n",
    "    previous_loss = np.inf\n",
    "\n",
    "    for epoch in range(maxEpochs+1):\n",
    "        # Shuffle the data\n",
    "        indices = np.random.permutation(q)\n",
    "        np.random.shuffle(indices) #barajeo aleatorio \n",
    "        X = X[indices,:]\n",
    "        Y = Y[indices,:]\n",
    "\n",
    "        #ciclo por mini lots, si fuera por lotes no seria el for \n",
    "        for j in range(n_minibatches): \n",
    "            #calcula la cantiad de los minilotes \n",
    "            X_Batch = X[j*batch_size : (j+1)*batch_size,:]            \n",
    "            Y_Batch = Y[j*batch_size : (j+1)*batch_size,:]\n",
    "            # Compute the gradients\n",
    "            A_Batch = designMatrix(tau,X_Batch)\n",
    "            Y_pred = model(A_Batch,THETA)\n",
    "            E_Batch = Y_Batch-Y_pred\n",
    "            Grad = gradient(A_Batch,E_Batch,THETA,lambda_param)\n",
    "\n",
    "            #apartir de aqui empieza el algoritmo RMSprop (aqui agregamos nuestro optimizador )\n",
    "\n",
    "            # Update accumulators\n",
    "            S = beta * S + (1 - beta) * (Grad**2)\n",
    "\n",
    "            # Update parameters\n",
    "            THETA -= learning_rate * Grad / (np.sqrt(S) + epsilon)\n",
    "            \n",
    "        if q % batch_size != 0:\n",
    "            X_Batch = X[(j+1)*batch_size : q,:]            \n",
    "            Y_Batch = Y[(j+1)*batch_size : q,:]\n",
    "            # Compute the gradients\n",
    "            A_Batch = designMatrix(tau,X_Batch)\n",
    "            Y_pred = model(A_Batch,THETA)\n",
    "            E_Batch = Y_Batch-Y_pred\n",
    "            Grad = gradient(A_Batch,E_Batch,THETA,lambda_param)\n",
    "\n",
    "            # Update accumulators\n",
    "            S = beta * S + (1 - beta) * (Grad**2)\n",
    "\n",
    "            # Update parameters\n",
    "            THETA -= learning_rate * Grad / (np.sqrt(S) + epsilon)\n",
    "\n",
    "        # Compute the loss\n",
    "        A = designMatrix(tau,X)\n",
    "        Yh = model(A,THETA)\n",
    "        current_loss = loss(Y, Yh, THETA, lambda_param)\n",
    "\n",
    "        # Progress\n",
    "        if (np.fmod(epoch,show) == 0):\n",
    "            print(this,end = \": \")\n",
    "            if np.isfinite(maxEpochs):\n",
    "                print(\"Epoch \",epoch, \"/\", maxEpochs,end = \" \")\n",
    "            if np.isfinite(stopping_threshold):\n",
    "                print(\", Performance %8.3e\" % current_loss, \"/\", stopping_threshold, end = \" \")\n",
    "                \n",
    "            print(\"\\n\")\n",
    "\n",
    "        if abs(previous_loss - current_loss) < stopping_threshold:\n",
    "            break\n",
    "\n",
    "        previous_loss = current_loss\n",
    "\n",
    "    return THETA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dce0672-1726-4fb3-a3e6-3aab07fdc16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = np.loadtxt('challenge01_syntheticdataset22.txt',delimiter=',')\n",
    "inputs  = data[:,0:2]\n",
    "targets = data[:,2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6430cf50-c019-4432-90e5-262e6b620e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test Split Data\n",
    "inputs_train, inputs_test, targets_train, targets_test = train_test_split(inputs, targets, random_state = 1, test_size = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3123f314-3b9e-49fd-9a31-8410e803d596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test Data\n",
    "# Train Data\n",
    "xTrain = inputs_train\n",
    "tTrain = targets_train\n",
    "# Test Data\n",
    "xTest = inputs_test\n",
    "tTest = targets_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2aa9d76-644f-44da-abb2-ed41c0b3895f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSprop: Epoch  0 / 1000 , Performance 3.090e+02 / 1e-06 \n",
      "\n",
      "RMSprop: Epoch  100 / 1000 , Performance 5.200e+01 / 1e-06 \n",
      "\n",
      "RMSprop: Epoch  200 / 1000 , Performance 4.991e-01 / 1e-06 \n",
      "\n",
      "RMSprop: Epoch  300 / 1000 , Performance 7.955e-04 / 1e-06 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find the optimal parameters m and b with RMSprop\n",
    "tau = 1\n",
    "lambda_param = 0.0\n",
    "\n",
    "THETA = rmsprop_optimization(\n",
    "    xTrain,\n",
    "    tTrain,\n",
    "    tau,\n",
    "    lambda_param,\n",
    "    maxEpochs=1000,\n",
    "    show=100,\n",
    "    batch_size=16,\n",
    "    learning_rate=0.01,\n",
    "    stopping_threshold=1e-6,\n",
    "    beta=0.9,\n",
    "    epsilon=1e-8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1373d87-2176-430e-9743-2d8011a11567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "# Train data\n",
    "A_train = designMatrix(tau,xTrain)\n",
    "outputTrain = model(A_train,THETA)\n",
    "# Test data\n",
    "A_test = designMatrix(tau,xTest)\n",
    "outputTest = model(A_test,THETA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d53337c-91c7-4005-876a-9d7d893c4f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999974443166\n"
     ]
    }
   ],
   "source": [
    "# R2 for raw train data\n",
    "R2_train = r2_score(tTrain.reshape(-1, 1),outputTrain.reshape(-1, 1))\n",
    "print(R2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707ad1c8-ced4-4b5d-90da-a4e5b8189c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.439502691451015e-07\n"
     ]
    }
   ],
   "source": [
    "# MSE for raw train data, #varianza \n",
    "MSE_train = mean_squared_error(tTrain.reshape(-1, 1),outputTrain.reshape(-1, 1))\n",
    "print(MSE_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d82810-9d79-4742-a11d-eb60c4a9e65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999969720091\n"
     ]
    }
   ],
   "source": [
    "# R2 for raw test data, datos crudos para los datos de prueba \n",
    "R2_test = r2_score(tTest.reshape(-1, 1),outputTest.reshape(-1, 1))\n",
    "print(R2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53807458-de5b-4934-afab-2debb61f3c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.454081627423006e-07\n"
     ]
    }
   ],
   "source": [
    "# MSE for raw test data, prueba no utilizados en el entrenamineto \n",
    "MSE_test = mean_squared_error(tTest.reshape(-1, 1),outputTest.reshape(-1, 1))\n",
    "print(MSE_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bce279e4-4659-4dc6-a3a8-6716cf6766af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.03228971  2.80426093]\n",
      " [-4.99994518  2.00005604]\n",
      " [ 7.00004526 -4.99995397]]\n"
     ]
    }
   ],
   "source": [
    "print(THETA)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
