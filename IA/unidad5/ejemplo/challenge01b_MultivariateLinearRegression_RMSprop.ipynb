{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b4ff91f-63e7-4239-9c22-d3f84505fcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ac7a334-8bc9-47c9-a33b-5b20ec5001e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(A, THETA):\n",
    "    \"\"\"\n",
    "    Multivariate Linear Regression Model, Yh = A*THETA\n",
    "    The matrix A is sometimes called the design matrix.\n",
    "    \"\"\"\n",
    "    return A.dot(THETA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2ca0e89-da15-4a28-8462-3f359b29f6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design Matrix\n",
    "def designMatrix(Tau,X):\n",
    "    q,_ = X.shape\n",
    "    for p in range(q):\n",
    "        M = powerVector(Tau,X[p,:])\n",
    "        if p == 0:\n",
    "            A = M\n",
    "            continue\n",
    "        A = np.vstack((A,M))\n",
    "    return A\n",
    "\n",
    "# Power Vector\n",
    "def powerVector(Tau,V):\n",
    "    if V.size == 0 or Tau == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        M = np.array([])\n",
    "        Z = V[:-1]\n",
    "        W = V[-1]\n",
    "        for k in range(Tau+1):\n",
    "            value = powerVector(Tau-k,Z)*(W**k)\n",
    "            M = np.append(M,value)\n",
    "        return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ca778b6-b754-4061-a015-232b8c55a3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial parameter number\n",
    "def polyParamsNumber(n,tau):\n",
    "    s = 0\n",
    "    for l in range(tau+1):\n",
    "        val = np.math.factorial(l+n-1)/np.math.factorial(n-1)\n",
    "        val = val/np.math.factorial(l)\n",
    "        s = s + val\n",
    "    return int(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8aabf335-98c9-4376-8519-e7b500e5f0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(Y_true, Y_pred, THETA, lambda_param):\n",
    "    \"\"\" Mean Squared Error \"\"\"\n",
    "    E = Y_true - Y_pred\n",
    "    SSE = np.square(np.linalg.norm(E, 'fro'))\n",
    "    Reg = (lambda_param/(2*E.shape[0]))*np.square(np.linalg.norm(THETA[1:,:], 'fro'))\n",
    "    MSE = SSE/(2*E.shape[0]) + Reg\n",
    "    return MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77eabc5e-7e80-407e-bde9-bb5d76410200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(A,E,THETA,lambda_param):\n",
    "    \"\"\" MSE Gradient \"\"\"\n",
    "    SSEGrad = -1.0*(A.T).dot(E)\n",
    "    MSEGrad = SSEGrad/E.shape[0]\n",
    "    MSEGrad[1:,:] = MSEGrad[1:,:] + (lambda_param/E.shape[0])*THETA[1:,:]\n",
    "    return MSEGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0305205-cda7-417a-855c-f57fa5ab328c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic RMSprop\n",
    "def rmsprop_optimization(\n",
    "    X,\n",
    "    Y,\n",
    "    tau=1,\n",
    "    lambda_param=0.0,\n",
    "    maxEpochs=100,\n",
    "    show=10,\n",
    "    batch_size=16,\n",
    "    learning_rate=0.01,\n",
    "    stopping_threshold=1e-6,\n",
    "    beta=0.9,\n",
    "    epsilon=1e-8,\n",
    "):\n",
    "    \"\"\"\n",
    "    RMSprop optimization with support for mini-batches.\n",
    "    \"\"\"\n",
    "    # Initialize the model parameters randomly\n",
    "    n = X.shape[1]\n",
    "    m = Y.shape[1]\n",
    "    rho = polyParamsNumber(n,tau)\n",
    "    THETA = np.random.randn(rho,m)\n",
    "    # Initialize accumulators for squared gradients\n",
    "    this = \"RMSprop\"\n",
    "    S = np.zeros((rho,m)) # Momentum\n",
    "    q = X.shape[0]\n",
    "    n_minibatches = q // batch_size\n",
    "    previous_loss = np.inf\n",
    "\n",
    "    for epoch in range(maxEpochs+1):\n",
    "        # Shuffle the data\n",
    "        indices = np.random.permutation(q)\n",
    "\n",
    "        X = X[indices,:]\n",
    "        Y = Y[indices,:]\n",
    "\n",
    "        for j in range(n_minibatches):\n",
    "            X_Batch = X[j*batch_size : (j+1)*batch_size,:]            \n",
    "            Y_Batch = Y[j*batch_size : (j+1)*batch_size,:]\n",
    "            # Compute the gradients\n",
    "            A_Batch = designMatrix(tau,X_Batch)\n",
    "            Y_pred = model(A_Batch,THETA)\n",
    "            E_Batch = Y_Batch-Y_pred\n",
    "            Grad = gradient(A_Batch,E_Batch,THETA,lambda_param)\n",
    "\n",
    "            # Update accumulators\n",
    "            S = beta * S + (1 - beta) * (Grad**2)\n",
    "\n",
    "            # Update parameters\n",
    "            THETA -= learning_rate * Grad / (np.sqrt(S) + epsilon)\n",
    "            \n",
    "        if q % batch_size != 0:\n",
    "            X_Batch = X[(j+1)*batch_size : q,:]            \n",
    "            Y_Batch = Y[(j+1)*batch_size : q,:]\n",
    "            # Compute the gradients\n",
    "            A_Batch = designMatrix(tau,X_Batch)\n",
    "            Y_pred = model(A_Batch,THETA)\n",
    "            E_Batch = Y_Batch-Y_pred\n",
    "            Grad = gradient(A_Batch,E_Batch,THETA,lambda_param)\n",
    "\n",
    "            # Update accumulators\n",
    "            S = beta * S + (1 - beta) * (Grad**2)\n",
    "\n",
    "            # Update parameters\n",
    "            THETA -= learning_rate * Grad / (np.sqrt(S) + epsilon)\n",
    "\n",
    "        # Compute the loss\n",
    "        A = designMatrix(tau,X)\n",
    "        Yh = model(A,THETA)\n",
    "        current_loss = loss(Y, Yh, THETA, lambda_param)\n",
    "\n",
    "        # Progress\n",
    "        if (np.fmod(epoch,show) == 0):\n",
    "            print(this,end = \": \")\n",
    "            if np.isfinite(maxEpochs):\n",
    "                print(\"Epoch \",epoch, \"/\", maxEpochs,end = \" \")\n",
    "            if np.isfinite(stopping_threshold):\n",
    "                print(\", Performance %8.3e\" % current_loss, \"/\", stopping_threshold, end = \" \")\n",
    "                \n",
    "            print(\"\\n\")\n",
    "\n",
    "        if abs(previous_loss - current_loss) < stopping_threshold:\n",
    "            break\n",
    "\n",
    "        previous_loss = current_loss\n",
    "\n",
    "    return THETA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dce0672-1726-4fb3-a3e6-3aab07fdc16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load dataset\n",
    "data = np.loadtxt('challenge01_syntheticdataset22.txt',delimiter=',')\n",
    "inputs  = data[:,0:2]\n",
    "targets = data[:,2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e256f9d6-6dbf-43e3-9cab-49c3fc3c2392",
   "metadata": {},
   "outputs": [],
   "source": [
    "#los datos ya estan normzalizados \n",
    "# Data normalization inputs and targets\n",
    "# Initialize the RobustScaler\n",
    "scalerInputs  = RobustScaler()\n",
    "scalerTargets = RobustScaler()\n",
    "# Transform the data\n",
    "robust_scaled_Inputs  = scalerInputs.fit_transform(inputs)\n",
    "robust_scaled_Targets = scalerTargets.fit_transform(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6430cf50-c019-4432-90e5-262e6b620e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test Split Data\n",
    "inputs_train, inputs_test, targets_train, targets_test = train_test_split(robust_scaled_Inputs, robust_scaled_Targets, random_state = 1, test_size = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3123f314-3b9e-49fd-9a31-8410e803d596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test Data\n",
    "# Train Data\n",
    "xTrain = inputs_train\n",
    "tTrain = targets_train\n",
    "# Test Data\n",
    "xTest = inputs_test\n",
    "tTest = targets_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2aa9d76-644f-44da-abb2-ed41c0b3895f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSprop: Epoch  0 / 1000 , Performance 1.562e+00 / 1e-06 \n",
      "\n",
      "RMSprop: Epoch  10 / 1000 , Performance 4.658e-01 / 1e-06 \n",
      "\n",
      "RMSprop: Epoch  20 / 1000 , Performance 9.994e-02 / 1e-06 \n",
      "\n",
      "RMSprop: Epoch  30 / 1000 , Performance 3.495e-03 / 1e-06 \n",
      "\n",
      "RMSprop: Epoch  40 / 1000 , Performance 2.644e-04 / 1e-06 \n",
      "\n",
      "RMSprop: Epoch  50 / 1000 , Performance 2.460e-04 / 1e-06 \n",
      "\n",
      "RMSprop: Epoch  60 / 1000 , Performance 4.498e-05 / 1e-06 \n",
      "\n",
      "RMSprop: Epoch  70 / 1000 , Performance 3.911e-05 / 1e-06 \n",
      "\n",
      "RMSprop: Epoch  80 / 1000 , Performance 3.666e-05 / 1e-06 \n",
      "\n",
      "RMSprop: Epoch  90 / 1000 , Performance 3.102e-05 / 1e-06 \n",
      "\n",
      "RMSprop: Epoch  100 / 1000 , Performance 2.641e-05 / 1e-06 \n",
      "\n",
      "RMSprop: Epoch  110 / 1000 , Performance 2.157e-06 / 1e-06 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find the optimal parameters m and b with RMSprop\n",
    "tau = 1\n",
    "lambda_param = 0.0\n",
    "\n",
    "THETA = rmsprop_optimization(\n",
    "    xTrain,\n",
    "    tTrain,\n",
    "    tau,\n",
    "    lambda_param,\n",
    "    maxEpochs=1000,\n",
    "    show=10,\n",
    "    batch_size=8,\n",
    "    learning_rate=0.01,\n",
    "    stopping_threshold=1e-6,\n",
    "    beta=0.9,\n",
    "    epsilon=1e-8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1373d87-2176-430e-9743-2d8011a11567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "# Train data\n",
    "A_train = designMatrix(tau,xTrain)\n",
    "outputTrain = model(A_train,THETA)\n",
    "# Test data\n",
    "A_test = designMatrix(tau,xTest)\n",
    "outputTest = model(A_test,THETA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7b18e1d-99ef-4a16-94de-1ca5cb32a54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse_transform in RobustScaler\n",
    "# Inverse transformation of training data for the outputs\n",
    "yTrain = scalerTargets.inverse_transform(tTrain)\n",
    "yhTrain = scalerTargets.inverse_transform(outputTrain)\n",
    "# Inverse transformation of the test data for the outputs\n",
    "yTest  = scalerTargets.inverse_transform(tTest)\n",
    "yhTest = scalerTargets.inverse_transform(outputTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d53337c-91c7-4005-876a-9d7d893c4f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999976736395545\n"
     ]
    }
   ],
   "source": [
    "# R2 for raw train data\n",
    "R2_train = r2_score(yTrain.reshape(-1, 1),yhTrain.reshape(-1, 1))\n",
    "print(R2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "707ad1c8-ced4-4b5d-90da-a4e5b8189c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000586168231344461\n"
     ]
    }
   ],
   "source": [
    "# MSE for raw train data\n",
    "MSE_train = mean_squared_error(yTrain.reshape(-1, 1),yhTrain.reshape(-1, 1))\n",
    "print(MSE_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0d82810-9d79-4742-a11d-eb60c4a9e65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999975029423862\n"
     ]
    }
   ],
   "source": [
    "# R2 for raw test data\n",
    "R2_test = r2_score(yTest.reshape(-1, 1),yhTest.reshape(-1, 1))\n",
    "print(R2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53807458-de5b-4934-afab-2debb61f3c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006147069761916673\n"
     ]
    }
   ],
   "source": [
    "# MSE for raw test data\n",
    "MSE_test = mean_squared_error(yTest.reshape(-1, 1),yhTest.reshape(-1, 1))\n",
    "print(MSE_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c7ca579-52e0-4e96-ada9-96da1b318798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.75482735e-04, -2.11584914e-04],\n",
       "       [-9.71276446e-01,  7.84296760e-01],\n",
       "       [ 6.80553144e-01, -9.82431657e-01]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "THETA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
