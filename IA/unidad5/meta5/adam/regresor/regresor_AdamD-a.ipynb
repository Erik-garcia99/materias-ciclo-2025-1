{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6989c686-6410-4c35-b570-b781f62df68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import math \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cddfae8-3056-4674-91f7-d5ad8b9547ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(A, THETA):\n",
    "    \"\"\"\n",
    "    Multivariate Linear Regression Model, Yh = A*THETA\n",
    "    The matrix A is sometimes called the design matrix.\n",
    "    \"\"\"\n",
    "    return A.dot(THETA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48db88d9-e7ce-4316-b6a6-066bda389377",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Design Matrix\n",
    "def designMatrix(Tau,X):\n",
    "    q,_ = X.shape\n",
    "    for p in range(q):\n",
    "        M = powerVector(Tau,X[p,:])\n",
    "        if p == 0:\n",
    "            A = M\n",
    "            continue\n",
    "        A = np.vstack((A,M))\n",
    "    return A\n",
    "\n",
    "# Power Vector M\n",
    "def powerVector(Tau, V):\n",
    "    if V.size == 0 or Tau == 0:\n",
    "        return np.array([[1.0]])  # Asegurar 2D\n",
    "    Z = V[:-1]\n",
    "    W = V[-1]\n",
    "    terms = []\n",
    "    for k in range(Tau + 1):\n",
    "        sub_terms = powerVector(Tau - k, Z)\n",
    "        for term in sub_terms.flatten():  # Manejar sub_terms 2D\n",
    "            terms.append(term * (W ** k))\n",
    "    return np.array([terms])  # Devolver como 2D (1, n_terms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43731c6d-2ed0-43a0-adc7-636ac125e605",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Polynomial parameter number\n",
    "def polyParamsNumber(n, tau):\n",
    "    return int(math.comb(n + tau, tau))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7a6f6d1-ef3e-415b-a2c2-b220eed9d451",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loss(Y_true, Y_pred, THETA, lambda_param):\n",
    "    \"\"\" Mean Squared Error \"\"\"\n",
    "    E = Y_true - Y_pred\n",
    "    SSE = np.square(np.linalg.norm(E, 'fro'))\n",
    "    Reg = (lambda_param/(2*E.shape[0]))*np.square(np.linalg.norm(THETA[1:,:], 'fro'))\n",
    "    MSE = SSE/(2*E.shape[0]) + Reg\n",
    "    return MSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45ad0634-8152-4ee4-a7aa-7766b0e327bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(A,E,THETA,lambda_param):\n",
    "    \"\"\" MSE Gradient \"\"\"\n",
    "    SSEGrad = -1.0*(A.T).dot(E)\n",
    "    MSEGrad = SSEGrad/E.shape[0]\n",
    "    MSEGrad[1:,:] = MSEGrad[1:,:] + (lambda_param/E.shape[0])*THETA[1:,:]\n",
    "    return MSEGrad\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fb262fa-8b2f-4c5e-beec-cef572291527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdamD Optimizer\n",
    "def adamd_optimization(\n",
    "    X,\n",
    "    Y,\n",
    "    tau,\n",
    "    lambda_param=0.0,\n",
    "    maxEpochs=100,\n",
    "    show=10,\n",
    "    batch_size=16,\n",
    "    learning_rate=0.001,\n",
    "    beta1=0.9,\n",
    "    beta2=0.999,\n",
    "    epsilon=1e-8,\n",
    "    stopping_threshold=1e-6,\n",
    "):\n",
    "    n = X.shape[1]\n",
    "    m = Y.shape[1]\n",
    "    rho = polyParamsNumber(n, tau)\n",
    "    THETA = np.random.randn(rho, m) * 0.01\n",
    "    q = X.shape[0]\n",
    "    \n",
    "    # inicializar momentos\n",
    "    m_t = np.zeros_like(THETA)\n",
    "    v_t = np.zeros_like(THETA)\n",
    "    \n",
    "    t = 0\n",
    "    previous_loss = np.inf\n",
    "\n",
    "    for epoch in range(maxEpochs + 1):\n",
    "        THETA_prev = THETA.copy()\n",
    "        current_loss = np.inf\n",
    "\n",
    "        if batch_size < q:\n",
    "            indices = np.random.permutation(q)\n",
    "            X = X[indices, :]\n",
    "            Y = Y[indices, :]\n",
    "\n",
    "        n_batches = q // batch_size\n",
    "        residual = q % batch_size\n",
    "        total_batches = n_batches + 1 if residual != 0 else n_batches\n",
    "\n",
    "        for batch_idx in range(total_batches):\n",
    "            t += 1  # incrementar timestep\n",
    "            \n",
    "            start = batch_idx * batch_size\n",
    "            end = start + batch_size\n",
    "            if batch_idx == total_batches - 1 and residual != 0:\n",
    "                end = start + residual\n",
    "\n",
    "            X_batch = X[start:end, :]\n",
    "            Y_batch = Y[start:end, :]\n",
    "            A_batch = designMatrix(tau, X_batch)\n",
    "            Y_pred = model(A_batch, THETA)\n",
    "            E_batch = Y_batch - Y_pred\n",
    "            g_t = gradient(A_batch, E_batch, THETA, lambda_param)\n",
    "            \n",
    "            # actualizar momentos\n",
    "            m_t = beta1 * m_t + (1 - beta1) * g_t\n",
    "            v_t = beta2 * v_t + (1 - beta2) * (g_t ** 2)\n",
    "            \n",
    "            # calcular learning rate para este timestep\n",
    "            alpha_t = learning_rate * np.sqrt(1 - beta2 ** t)\n",
    "            \n",
    "            # actualizar parametros\n",
    "            THETA -= alpha_t * m_t / (np.sqrt(v_t) + epsilon)\n",
    "\n",
    "        A = designMatrix(tau, X)\n",
    "        Yh = model(A, THETA)\n",
    "        current_loss = loss(Y, Yh, THETA, lambda_param)\n",
    "\n",
    "        if epoch % show == 0:\n",
    "            print(f\"Epoch {epoch}: Loss={current_loss:.3e}, lr={alpha_t:.2e}\")\n",
    "\n",
    "        if abs(previous_loss - current_loss) < stopping_threshold:\n",
    "            break\n",
    "            \n",
    "        previous_loss = current_loss\n",
    "\n",
    "    return THETA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd5b8865-f27d-4811-925b-def74376384f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "mat = sp.loadmat('engine_dataset.mat')\n",
    "inputs  = mat['engineInputs'].T\n",
    "targets = mat['engineTargets'].T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc319e77-f393-4b68-afd5-c84233b8f609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test Split Data\n",
    "inputs_train, inputs_test, targets_train, targets_test = train_test_split(inputs, targets, random_state = 1, test_size = 0.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7166072-1c3f-42c1-a170-4bb57d8e05e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test Data\n",
    "xTrain = inputs_train\n",
    "tTrain = targets_train\n",
    "xTest = inputs_test\n",
    "tTest = targets_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b00cc1e-0ff0-4f3f-9926-e7e668a552b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss=9.672e+07, lr=1.09e-04\n",
      "Epoch 500: Loss=7.138e+04, lr=9.99e-04\n",
      "Epoch 1000: Loss=6.377e+04, lr=1.00e-03\n",
      "Epoch 1500: Loss=3.531e+04, lr=1.00e-03\n",
      "Epoch 2000: Loss=7.423e+04, lr=1.00e-03\n",
      "Epoch 2500: Loss=6.991e+04, lr=1.00e-03\n",
      "Epoch 3000: Loss=6.734e+04, lr=1.00e-03\n",
      "Epoch 3500: Loss=2.907e+04, lr=1.00e-03\n",
      "Epoch 4000: Loss=3.246e+04, lr=1.00e-03\n",
      "Epoch 4500: Loss=2.477e+04, lr=1.00e-03\n",
      "Epoch 5000: Loss=2.254e+04, lr=1.00e-03\n",
      "Epoch 5500: Loss=2.766e+04, lr=1.00e-03\n",
      "Epoch 6000: Loss=4.406e+04, lr=1.00e-03\n",
      "Epoch 6500: Loss=6.157e+04, lr=1.00e-03\n",
      "Epoch 7000: Loss=1.653e+04, lr=1.00e-03\n",
      "Epoch 7500: Loss=3.464e+04, lr=1.00e-03\n",
      "Epoch 8000: Loss=3.564e+04, lr=1.00e-03\n",
      "Epoch 8500: Loss=1.840e+04, lr=1.00e-03\n",
      "Epoch 9000: Loss=1.502e+04, lr=1.00e-03\n",
      "Epoch 9500: Loss=4.339e+04, lr=1.00e-03\n",
      "Epoch 10000: Loss=1.613e+04, lr=1.00e-03\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#mini lote\n",
    "# Find the optimal parameters with AdamD\n",
    "tau = 2\n",
    "lambda_param = 0.1\n",
    "\n",
    "THETA = adamd_optimization(\n",
    "    xTrain,\n",
    "    tTrain,\n",
    "    tau=tau,\n",
    "    lambda_param=lambda_param,\n",
    "    maxEpochs=10000,\n",
    "    show=500,\n",
    "    batch_size=64,\n",
    "    learning_rate=0.001,\n",
    "    beta1=0.9,\n",
    "    beta2=0.999,\n",
    "    epsilon=1e-8,\n",
    "    stopping_threshold=1e-6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "278fc824-7160-4ddc-b8ad-109321cacea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make predictions\n",
    "# Train data\n",
    "A_train = designMatrix(tau,xTrain)\n",
    "outputTrain = model(A_train,THETA)\n",
    "# Test data\n",
    "A_test = designMatrix(tau,xTest)\n",
    "outputTest = model(A_test,THETA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d453c428-543a-45ad-a14d-5263b9eb0428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9381630934043915\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Metrics\n",
    "# Train data\n",
    "R2_train = r2_score(tTrain.reshape(-1, 1), outputTrain.reshape(-1, 1))\n",
    "print(R2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b524c044-6c60-4f02-9b9f-f9057e8cb803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16126.81710705816\n"
     ]
    }
   ],
   "source": [
    "MSE_train = mean_squared_error(tTrain.reshape(-1, 1), outputTrain.reshape(-1, 1))\n",
    "print(MSE_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1746c732-3407-45fa-a933-a43d7482440a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9424683362277272\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test data\n",
    "R2_test = r2_score(tTest.reshape(-1, 1), outputTest.reshape(-1, 1))\n",
    "print(R2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9a4b9c5-fdd6-4fcd-b225-e2221a772238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16261.71687615213\n"
     ]
    }
   ],
   "source": [
    "MSE_test = mean_squared_error(tTest.reshape(-1, 1), outputTest.reshape(-1, 1))\n",
    "print(MSE_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "119a83da-6fe7-43d6-86f9-f0f35631f718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.64145697e-01,  6.79223419e-01],\n",
       "       [ 4.93389517e+00,  1.25978079e+01],\n",
       "       [-1.73465728e-03, -3.03313080e-02],\n",
       "       [-3.93973210e-02,  3.71400335e-01],\n",
       "       [ 1.22338865e-03,  1.25363043e-04],\n",
       "       [-4.99357791e-05, -2.97922822e-04]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "THETA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
